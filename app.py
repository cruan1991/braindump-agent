#!/usr/bin/env python3
"""
BrainDump Agent - Web GUI (FastAPI)
"""

from __future__ import annotations

import os
import re
import random
import json
from datetime import date, datetime
from pathlib import Path
from typing import List, Optional, Dict, Any

from fastapi import FastAPI
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
from groq import Groq

# --- Config ---

ROOT = Path(__file__).parent
PROMPT_PATH = ROOT / "prompts" / "brain_dump.md"
STATE_PATH = ROOT / "state.md"
RUNS_DIR = ROOT / "runs"
SUMMARIES_DIR = ROOT / "summaries"

DEFAULT_MODEL = os.environ.get("GROQ_MODEL", "llama-3.3-70b-versatile")

DONE_ARCHIVE_HEADER = "## Done Archive"
DONE_LINE_RE = re.compile(r"^\s*-\s*\[x\]\s*(.+?)\s*$", re.IGNORECASE)
DATED_DONE_RE = re.compile(r"^\s*-\s*\[x\]\s*(\d{4}-\d{2}-\d{2})\s*â€”\s*(.+?)\s*$")
META_RE = re.compile(r"^<!--\s*meta:\s*(\{.*\})\s*-->$")

# --- Praise Pools (by style) ---

PRAISE_POOLS = {
    "snarky": [
        "è¡Œï¼Œä½ ç¡®å®åŠ¨äº†ã€‚",
        "å±…ç„¶åšå®Œäº†ï¼Œå¥‡è¿¹ã€‚",
        "å¯ä»¥ï¼Œåˆ«ä¸Šå¤´ã€‚",
        "å®Œäº‹äº†ï¼Œåˆ«é£˜ã€‚",
        "è¡Œå§ï¼Œå‹‰å¼ºè®¤å¯ã€‚",
        "æ€»ç®—æ˜¯å¹²äº†ç‚¹æ­£äº‹ã€‚",
        "è¿™ä¸å°±åšå®Œäº†ï¼Œä¹‹å‰çº ç»“å•¥ã€‚",
        "å¥½ï¼Œæ”¶ã€‚åˆ«ç»§ç»­äº†ã€‚",
    ],
    "neutral": [
        "å·²å®Œæˆã€‚",
        "åšå®Œäº†ã€‚",
        "ä¸€ä»¶äº‹ï¼Œç»“æŸã€‚",
        "åˆ’æ‰ã€‚",
        "å®Œæˆï¼Œä¸‹ä¸€ä¸ªã€‚",
        "æå®šã€‚",
        "OK.",
        "Done.",
    ],
    "warm": [
        "åšå¾—å¥½ï¼Œè¾›è‹¦äº†ã€‚",
        "å®Œæˆäº†ï¼ŒçœŸæ£’ã€‚",
        "è¿™ä¸€æ­¥èµ°å¾—å¾ˆå¥½ã€‚",
        "ä½ åšåˆ°äº†ï¼Œä¼‘æ¯ä¸€ä¸‹å§ã€‚",
        "å¾ˆå¥½ï¼Œå¯ä»¥å–˜å£æ°”äº†ã€‚",
        "å®Œæˆäº†ï¼Œç»™è‡ªå·±ç‚¹ä¸ªèµã€‚",
        "ä¸€ä»¶äº‹æå®šï¼Œç»§ç»­åŠ æ²¹ã€‚",
        "ä¸é”™ï¼Œä»Šå¤©åˆè¿›æ­¥äº†ã€‚",
    ],
}

SAFETY_NOTES = {
    "snarky": "åˆ°è¿™æ”¶æ‰‹ï¼Œåˆ«è´ªã€‚",
    "neutral": "å¯ä»¥åœäº†ã€‚",
    "warm": "å…ˆåˆ°è¿™é‡Œï¼Œåˆ«ç´¯ç€è‡ªå·±ã€‚",
}

SHUTDOWN_NOTES = {
    "snarky": "ä»Šå¤©å¤Ÿäº†ï¼Œåˆ«å†å·äº†ã€‚",
    "neutral": "ä»Šæ—¥æ¨èæ¬¡æ•°å·²ç”¨å®Œï¼Œæ”¶å·¥ã€‚",
    "warm": "ä»Šå¤©å·²ç»å¾ˆåŠªåŠ›äº†ï¼Œä¼‘æ¯å§ã€‚",
}

# å®Œæˆ parking ä»»åŠ¡çš„ç‰¹æ®Šæç¤º
PARKING_HINTS = {
    "snarky": {
        "main_first": "ä¸»çº¿ä»»åŠ¡è¿˜æ²¡åŠ¨å‘¢ï¼Œä¸å¦‚å…ˆæé‚£ä¸ªï¼Ÿ",
        "all_done": "å…¨éƒ¨æå®šäº†ï¼Ÿä»Šå¤©ä½ æ˜¯ç¥ã€‚",
        "bonus": "ä¸»çº¿æ¸…äº†ï¼Œè¿™ä¸ªç®—åŠ åˆ†é¡¹ã€‚",
    },
    "neutral": {
        "main_first": "ä¸»çº¿ä»»åŠ¡è¿˜æ²¡å®Œæˆï¼Œå»ºè®®å…ˆåšä¸»çº¿ã€‚",
        "all_done": "æ­å–œï¼Œä»Šå¤©çš„ä»»åŠ¡å…¨éƒ¨å®Œæˆã€‚",
        "bonus": "ä¸»çº¿å·²å®Œæˆï¼Œè¿™ä¸ªæ˜¯é¢å¤–æ”¶è·ã€‚",
    },
    "warm": {
        "main_first": "ä¸»çº¿ä»»åŠ¡è¿˜åœ¨ç­‰ä½ å‘¢ï¼Œè¦ä¸è¦å…ˆå»çœ‹çœ‹ï¼Ÿ",
        "all_done": "å¤ªæ£’äº†ï¼ä»Šå¤©è¶…é¢å®Œæˆï¼Œç»™è‡ªå·±ä¸€ä¸ªå¤§å¤§çš„èµï¼",
        "bonus": "ä¸»çº¿éƒ½åšå®Œäº†ï¼Œè¿™ä¸ªç®—æ˜¯é¢å¤–çš„æˆå°±ï¼ŒçœŸæ£’ï¼",
    },
}

# --- Micro Actions Library ---

MICRO_ACTIONS = [
    {
        "id": "log_result",
        "title": "è®°å½•ç»“æœ",
        "steps": "æŠŠåˆšå®Œæˆé‚£ä»¶äº‹çš„ç»“æœå†™ä¸€è¡Œåˆ° stateï¼ˆæ¯”å¦‚ç¡®è®¤å·/å…³é”®ä¿¡æ¯ï¼‰",
        "eta_seconds": 60,
        "type": "closing",
    },
    {
        "id": "open_doc",
        "title": "æ‰“å¼€æ˜å¤©è¦ç”¨çš„æ–‡æ¡£",
        "steps": "æŠŠéœ€è¦æ˜å¤©ç”¨çš„æ–‡æ¡£æ‰“å¼€ï¼Œåœåœ¨é‚£ï¼Œä¸æ”¹",
        "eta_seconds": 45,
        "type": "prep",
    },
    {
        "id": "copy_phone",
        "title": "å¤åˆ¶ç”µè¯å·ç ",
        "steps": "æŠŠéœ€è¦æ‰“ç”µè¯çš„å·ç å¤åˆ¶åˆ° state é¡¶éƒ¨",
        "eta_seconds": 30,
        "type": "prep",
    },
    {
        "id": "write_first_step",
        "title": "å†™ä¸‹ç¬¬ä¸€æ­¥",
        "steps": "æŠŠä¸€ä¸ªä»»åŠ¡æ‹†æˆç¬¬ä¸€æ­¥ï¼Œå†™æˆä¸€å¥è¯",
        "eta_seconds": 60,
        "type": "prep",
    },
    {
        "id": "drink_water",
        "title": "å–æ°´",
        "steps": "ç«™èµ·æ¥ï¼Œå€’æ¯æ°´ï¼Œå–æ‰",
        "eta_seconds": 60,
        "type": "reset",
    },
    {
        "id": "stretch",
        "title": "ä¼¸å±• 60 ç§’",
        "steps": "ç«™èµ·æ¥ï¼Œä¼¸å±•ä¸€ä¸‹è„–å­å’Œè‚©è†€",
        "eta_seconds": 60,
        "type": "reset",
    },
    {
        "id": "walk",
        "title": "èµ°åŠ¨ä¸€ä¸‹",
        "steps": "ç¦»å¼€åº§ä½ï¼Œèµ°å‡ æ­¥ï¼Œ60 ç§’åå›æ¥",
        "eta_seconds": 60,
        "type": "reset",
    },
    {
        "id": "close_tabs",
        "title": "å…³æ‰å¤šä½™æ ‡ç­¾é¡µ",
        "steps": "æŠŠåˆšæ‰åšå®Œçš„ç›¸å…³æ ‡ç­¾é¡µå…³æ‰ï¼Œåªç•™éœ€è¦çš„",
        "eta_seconds": 45,
        "type": "closing",
    },
    {
        "id": "note_blocker",
        "title": "è®°ä¸‹å¡ç‚¹",
        "steps": "å¦‚æœæœ‰å¡ä½çš„åœ°æ–¹ï¼Œå†™ä¸€å¥è¯åˆ° state é¡¶éƒ¨",
        "eta_seconds": 45,
        "type": "closing",
    },
    {
        "id": "set_reminder",
        "title": "è®¾ä¸ªæé†’",
        "steps": "å¦‚æœæ˜å¤©æœ‰æˆªæ­¢æ—¥æœŸï¼Œæ‰“å¼€æ‰‹æœºè®¾ä¸ªé—¹é’Ÿ",
        "eta_seconds": 60,
        "type": "prep",
    },
]

MAX_MICRO_ACTIONS_PER_DAY = 2


# --- Helpers ---

def read_text(path: Path) -> str:
    if not path.exists():
        return ""
    return path.read_text(encoding="utf-8").strip()


def write_text(path: Path, text: str) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(text.rstrip() + "\n", encoding="utf-8")


def timestamp() -> str:
    return datetime.now().strftime("%Y%m%d_%H%M%S")


def timestamp_human() -> str:
    return datetime.now().strftime("%Y-%m-%d %H:%M")


# --- Metadata in state.md ---

def get_metadata(text: str) -> Dict[str, Any]:
    """Extract metadata from <!-- meta: {...} --> line"""
    for line in text.splitlines():
        m = META_RE.match(line.strip())
        if m:
            try:
                return json.loads(m.group(1))
            except:
                pass
    return {}


def set_metadata(text: str, meta: Dict[str, Any]) -> str:
    """Set or update metadata line in text"""
    meta_line = f"<!-- meta: {json.dumps(meta, ensure_ascii=False)} -->"
    lines = text.splitlines()
    new_lines = [line for line in lines if not META_RE.match(line.strip())]
    # Add metadata at the very end
    new_lines.append("")
    new_lines.append(meta_line)
    return "\n".join(new_lines).strip()


def strip_metadata(text: str) -> str:
    """Remove metadata line from text"""
    return "\n".join(line for line in text.splitlines() if not META_RE.match(line.strip())).strip()


def get_praise_style() -> str:
    raw = read_text(STATE_PATH)
    meta = get_metadata(raw)
    return meta.get("praise_style", "neutral")


def set_praise_style(style: str) -> None:
    raw = read_text(STATE_PATH)
    meta = get_metadata(raw)
    meta["praise_style"] = style
    new_text = set_metadata(strip_metadata(raw), meta)
    write_text(STATE_PATH, new_text)


def get_micro_action_count() -> int:
    """Get today's micro action recommendation count"""
    raw = read_text(STATE_PATH)
    meta = get_metadata(raw)
    count_date = meta.get("micro_action_date", "")
    if count_date != date.today().isoformat():
        return 0
    return meta.get("micro_action_count", 0)


def increment_micro_action_count() -> int:
    """Increment and return new count"""
    raw = read_text(STATE_PATH)
    meta = get_metadata(raw)
    today_str = date.today().isoformat()
    
    if meta.get("micro_action_date") != today_str:
        meta["micro_action_date"] = today_str
        meta["micro_action_count"] = 1
    else:
        meta["micro_action_count"] = meta.get("micro_action_count", 0) + 1
    
    new_text = set_metadata(strip_metadata(raw), meta)
    write_text(STATE_PATH, new_text)
    return meta["micro_action_count"]


# --- Parsing ---

def split_done_archive(text: str) -> tuple[str, List[str]]:
    text = strip_metadata(text)
    if DONE_ARCHIVE_HEADER not in text:
        return text.strip(), []
    main, tail = text.split(DONE_ARCHIVE_HEADER, 1)
    archive_lines = [line.strip() for line in tail.splitlines() if line.strip().lower().startswith("- [x]")]
    return main.strip(), archive_lines


def extract_done_lines(text: str) -> List[str]:
    return [line.strip() for line in text.splitlines() if DONE_LINE_RE.match(line)]


def remove_done_lines(text: str) -> str:
    return "\n".join(line for line in text.splitlines() if not DONE_LINE_RE.match(line)).strip()


def normalize_done_item(raw_line: str, done_date: date) -> str:
    line = raw_line.strip()
    if DATED_DONE_RE.match(line):
        m = DATED_DONE_RE.match(line)
        return f"- [x] {m.group(1)} â€” {m.group(2).strip()}"
    m = DONE_LINE_RE.match(line)
    if not m:
        return line
    return f"- [x] {done_date.isoformat()} â€” {m.group(1).strip()}"


def dedupe_preserve_order(items: List[str]) -> List[str]:
    seen = set()
    out = []
    for it in items:
        if it not in seen:
            out.append(it)
            seen.add(it)
    return out


def parse_state_sections(text: str) -> dict:
    """è§£æ state.md ä¸ºç»“æ„åŒ–æ•°æ®"""
    text = strip_metadata(text)
    main_content, archive_lines = split_done_archive(text)
    
    today_tasks = []
    parking_tasks = []
    extra_tasks = []
    
    current_section = None
    
    for line in main_content.splitlines():
        line_stripped = line.strip()
        line_lower = line_stripped.lower()
        
        if "ä»Šå¤©åšè¿™å‡ ä»¶" in line_stripped or "today" in line_lower:
            current_section = "today"
            continue
        elif "å¯ä»¥ä¸åš" in line_stripped or "parking" in line_lower:
            current_section = "parking"
            continue
        elif "å¦‚æœè¿˜æœ‰ä½™åŠ›" in line_stripped or "extra" in line_lower:
            current_section = "extra"
            continue
        elif line_stripped.startswith("## ") or line_stripped.startswith("---"):
            continue
        
        task_match = re.match(r"^\d+\.\s*\*\*(.+?)\*\*", line_stripped)
        if task_match:
            task_name = task_match.group(1).strip()
            if current_section == "today":
                today_tasks.append({"name": task_name, "hint": ""})
            continue
        
        if line_stripped.startswith("â†’") and today_tasks and current_section == "today":
            today_tasks[-1]["hint"] = line_stripped[1:].strip()
            continue
        
        parking_match = re.match(r"^-\s*(.+?)\s*â€”\s*(.+)$", line_stripped)
        if parking_match and current_section == "parking":
            parking_tasks.append({"name": parking_match.group(1).strip(), "reason": parking_match.group(2).strip()})
            continue
        
        if line_stripped.startswith("- ") and current_section == "extra":
            extra_tasks.append(line_stripped[2:].strip())
    
    done_items = []
    for line in archive_lines:
        m = DATED_DONE_RE.match(line)
        if m:
            done_items.append({"date": m.group(1), "text": m.group(2).strip()})
        else:
            m2 = DONE_LINE_RE.match(line)
            if m2:
                done_items.append({"date": "", "text": m2.group(1).strip()})
    
    return {
        "today": today_tasks,
        "parking": parking_tasks,
        "extra": extra_tasks,
        "done": done_items,
    }


# --- Weekly Summary ---

def update_weekly_summary(archive_lines: List[str]) -> None:
    from dataclasses import dataclass
    
    @dataclass(frozen=True)
    class DoneEntry:
        when: date
        text: str
    
    entries = []
    for line in archive_lines:
        m = DATED_DONE_RE.match(line.strip())
        if m:
            entries.append(DoneEntry(when=date.fromisoformat(m.group(1)), text=m.group(2).strip()))
    
    if not entries:
        return
    
    today = date.today()
    y, w, _ = today.isocalendar()
    this_week = [e for e in entries if e.when.isocalendar()[:2] == (y, w)]
    
    if not this_week:
        return
    
    by_day = {}
    for e in this_week:
        by_day.setdefault(e.when, []).append(e.text)
    
    days = sorted(by_day.keys())
    total = sum(len(v) for v in by_day.values())
    
    lines = [f"# Done æ‘˜è¦ â€” {y}-W{w:02d}", "", f"- æ€»å®Œæˆæ¡ç›®ï¼š**{total}**"]
    if days:
        lines.append(f"- è¦†ç›–æ—¥æœŸï¼š{days[0].isoformat()} ~ {days[-1].isoformat()}")
    lines += ["", "## æŒ‰å¤©", ""]
    for d in days:
        lines.append(f"### {d.isoformat()}ï¼ˆ{len(by_day[d])}ï¼‰")
        lines.extend(f"- {item}" for item in by_day[d])
        lines.append("")
    
    SUMMARIES_DIR.mkdir(exist_ok=True)
    out_path = SUMMARIES_DIR / f"weekly_{y}-W{w:02d}.md"
    write_text(out_path, "\n".join(lines).strip())


# --- Micro Action Selection ---

def select_micro_action(completed_task: str, remaining_tasks: List[dict]) -> Optional[dict]:
    """Select a micro action based on context"""
    # Prioritize by type
    candidates = []
    
    # Closing actions for completed task
    closing_actions = [a for a in MICRO_ACTIONS if a["type"] == "closing"]
    candidates.extend(closing_actions)
    
    # Prep actions if there are remaining tasks
    if remaining_tasks:
        prep_actions = [a for a in MICRO_ACTIONS if a["type"] == "prep"]
        candidates.extend(prep_actions)
    
    # Reset actions (always available)
    reset_actions = [a for a in MICRO_ACTIONS if a["type"] == "reset"]
    candidates.extend(reset_actions)
    
    if not candidates:
        return None
    
    # Randomly select one
    action = random.choice(candidates)
    return {
        "title": action["title"],
        "steps": action["steps"],
        "eta_seconds": action["eta_seconds"],
    }


# --- Groq ---

def generate_new_state(prompt: str, brain_dump: str, completed_today: List[str]) -> str:
    client = Groq(api_key=os.environ["GROQ_API_KEY"])
    today_str = date.today().isoformat()

    done_context = ""
    if completed_today:
        done_context = "ï¼ˆå·²å½’æ¡£çš„å®Œæˆé¡¹ï¼Œä¸è¦å†åˆ—å‡ºï¼‰\n" + "\n".join(completed_today) + "\n\n"

    user_message = f"""{done_context}ã€ç”¨æˆ·çš„ brain dump / å½“å‰çŠ¶æ€ã€‘

{brain_dump if brain_dump else "ï¼ˆç©ºï¼‰"}

---

è¯·æ ¹æ®ä»¥ä¸Šå†…å®¹ï¼š

1. **è¯†åˆ«ç”¨æˆ·è¯´å®Œæˆäº†ä»€ä¹ˆ**ï¼ˆæ¯”å¦‚"å†™å®Œäº†"ã€"åšå®Œäº†"ã€"æå®šäº†"ã€"å¼„å¥½äº†"ï¼‰
   - å¦‚æœç”¨æˆ·è¯´å®Œæˆäº†æŸäº‹ï¼Œåœ¨æœ€åè¾“å‡ºä¸€ä¸ª `## åˆšå®Œæˆ` åŒºå—

2. **ç”Ÿæˆæ–°çš„ä»»åŠ¡æ¸…å•**ï¼Œæ ¼å¼ï¼š

## ä»Šå¤©åšè¿™å‡ ä»¶å°±å¤Ÿäº†

1. **ä»»åŠ¡å**  
   â†’ æ€ä¹ˆå¼€å§‹ï¼ˆ15åˆ†é’Ÿå†…èƒ½åŠ¨æ‰‹ï¼‰

ï¼ˆæœ€å¤š 3-5 ä¸ªï¼Œé€‰æœ€å®¹æ˜“å¼€å§‹çš„ï¼‰

---

## ä»Šå¤©å¯ä»¥ä¸åš

- ä»»åŠ¡ â€” åŸå› 

ï¼ˆ**é‡è¦ï¼šæ‰€æœ‰ç”¨æˆ·æåˆ°ä½†æ²¡æ”¾è¿›"ä»Šå¤©åš"çš„ä»»åŠ¡ï¼Œå¿…é¡»å…¨éƒ¨æ”¾åœ¨è¿™é‡Œï¼Œä¸èƒ½ä¸¢å¼ƒä»»ä½•ä»»åŠ¡**ï¼‰

---

## å¦‚æœè¿˜æœ‰ä½™åŠ›

- å¯é€‰ä»»åŠ¡

## åˆšå®Œæˆ
- [x] {today_str} â€” xxxï¼ˆå¦‚æœç”¨æˆ·è¯´å®Œæˆäº†ä»€ä¹ˆï¼‰

**å…³é”®è§„åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š**
1. ç”¨æˆ·æåˆ°çš„æ‰€æœ‰ä»»åŠ¡éƒ½ä¸èƒ½ä¸¢å¤±
2. "ä»Šå¤©åš"æœ€å¤š 3-5 ä¸ªï¼Œä¼˜å…ˆé€‰æœ€å®¹æ˜“å¼€å§‹çš„
3. å‰©ä½™çš„ä»»åŠ¡å¿…é¡»å…¨éƒ¨æ”¾åˆ°"å¯ä»¥ä¸åš"é‡Œï¼Œç»™å‡ºæ¨è¿ŸåŸå› 
4. å¦‚æœç”¨æˆ·è¯´å®Œæˆäº†æŸäº‹ï¼Œæ”¾åˆ°"åˆšå®Œæˆ"åŒºå—
5. åªè¾“å‡ºä¸Šé¢çš„æ ¼å¼ï¼Œä¸è¦è§£é‡Š"""

    response = client.chat.completions.create(
        model=DEFAULT_MODEL,
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": user_message},
        ],
        temperature=0.3,
    )
    return response.choices[0].message.content.strip()


def run_replan() -> dict:
    """æ‰§è¡Œé‡æ’æµç¨‹ï¼Œè¿”å›è§£æåçš„ç»“æœ"""
    prompt = read_text(PROMPT_PATH)
    raw_state = read_text(STATE_PATH)

    if not raw_state:
        return {"today": [], "parking": [], "extra": [], "done": []}

    # Preserve metadata
    meta = get_metadata(raw_state)
    
    # ä¿ç•™åŸå§‹ä»»åŠ¡éƒ¨åˆ†ï¼ˆç”¨äºå›é€€ï¼‰
    original_main, archive_lines = split_done_archive(raw_state)
    original_tasks_section = original_main  # å¤‡ä»½
    
    done_in_main = extract_done_lines(original_main)
    brain_dump = remove_done_lines(original_main)

    today = date.today()
    newly_done_from_user = [normalize_done_item(x, today) for x in done_in_main]

    new_tasks = generate_new_state(prompt, brain_dump, archive_lines + newly_done_from_user)

    model_done = extract_done_lines(new_tasks)
    model_done_normalized = [normalize_done_item(x, today) for x in model_done]

    clean_tasks = new_tasks
    if DONE_ARCHIVE_HEADER in clean_tasks:
        clean_tasks = clean_tasks.split(DONE_ARCHIVE_HEADER, 1)[0].strip()
    if "## åˆšå®Œæˆ" in clean_tasks:
        clean_tasks = clean_tasks.split("## åˆšå®Œæˆ", 1)[0].strip()
    clean_tasks = remove_done_lines(clean_tasks)

    combined_archive = dedupe_preserve_order(archive_lines + newly_done_from_user + model_done_normalized)

    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è¿”å›äº†æœ‰æ•ˆä»»åŠ¡
    has_today_tasks = "ä»Šå¤©åšè¿™å‡ ä»¶" in clean_tasks or "## Today" in clean_tasks
    
    if not clean_tasks.strip() or not has_today_tasks:
        # æ¨¡å‹æ²¡æœ‰è¿”å›æœ‰æ•ˆä»»åŠ¡ï¼Œç”Ÿæˆä¸€ä¸ªé»˜è®¤çŠ¶æ€
        clean_tasks = """## ä»Šå¤©åšè¿™å‡ ä»¶å°±å¤Ÿäº†

1. **ä¼‘æ¯ä¸€ä¸‹**  
   â†’ ä»Šå¤©å·²ç»å®Œæˆå¾ˆå¤šäº†ï¼Œå¯ä»¥æ”¾æ¾

---

## ä»Šå¤©å¯ä»¥ä¸åš

- å…¶ä»–ä»»åŠ¡ â€” æ˜å¤©å†è¯´

---

## å¦‚æœè¿˜æœ‰ä½™åŠ›

- æƒ³æƒ³æ˜å¤©è¦åšä»€ä¹ˆ"""

    final_state = clean_tasks
    if combined_archive:
        final_state += f"\n\n{DONE_ARCHIVE_HEADER}\n" + "\n".join(combined_archive)
    
    # Restore metadata
    if meta:
        final_state = set_metadata(final_state, meta)

    write_text(STATE_PATH, final_state)

    RUNS_DIR.mkdir(exist_ok=True)
    write_text(RUNS_DIR / f"state_{timestamp()}.md", final_state)

    update_weekly_summary(combined_archive)

    return parse_state_sections(final_state)


# --- FastAPI ---

app = FastAPI(title="BrainDump Agent")

STATIC_DIR = ROOT / "static"
STATIC_DIR.mkdir(exist_ok=True)
app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")


class CaptureRequest(BaseModel):
    text: str


class CompleteRequest(BaseModel):
    task_text: str
    note: Optional[str] = ""


class StyleRequest(BaseModel):
    praise_style: str


class MicroActionRequest(BaseModel):
    action_title: str


@app.get("/")
async def index():
    return FileResponse(STATIC_DIR / "index.html")


@app.get("/api/state")
async def get_state():
    raw = read_text(STATE_PATH)
    state = parse_state_sections(raw)
    state["praise_style"] = get_praise_style()
    return state


@app.post("/api/style")
async def set_style(req: StyleRequest):
    if req.praise_style not in ["snarky", "neutral", "warm"]:
        req.praise_style = "neutral"
    set_praise_style(req.praise_style)
    return {"praise_style": req.praise_style}


def detect_all_done(text: str) -> tuple[bool, bool]:
    """æ£€æµ‹ç”¨æˆ·æ˜¯å¦è¯´æ‰€æœ‰äº‹éƒ½åšå®Œäº†
    è¿”å› (today_all_done, include_parking)
    """
    # å…ˆæ£€æµ‹æ˜¯å¦åŒ…æ‹¬ parkingï¼ˆæ‰€æœ‰æ‰€æœ‰ã€å…¨éƒ¨å…¨éƒ¨ã€è¿XXä¹Ÿï¼‰
    include_parking_patterns = [
        r"æ‰€æœ‰.{0,3}æ‰€æœ‰",
        r"å…¨éƒ¨.{0,3}å…¨éƒ¨",
        r"è¿.{0,10}(?:å¯ä»¥ä¸åš|parking|ä¸åšçš„|å¯ä»¥ä¸åšçš„).{0,5}ä¹Ÿ",
        r"(?:å¯ä»¥ä¸åš|ä¸åšçš„).{0,5}ä¹Ÿ.{0,5}(?:åšå®Œ|å®Œæˆ|æå®š)",
        r"å½»åº•.{0,5}(?:æ¸…ç©º|åšå®Œ|å®Œæˆ)",
        r"ä¸€ä¸ªä¸å‰©",
        r"ç»Ÿç»Ÿ",
    ]
    
    include_parking = False
    for pattern in include_parking_patterns:
        if re.search(pattern, text):
            include_parking = True
            break
    
    # å¦‚æœæ£€æµ‹åˆ° include_parkingï¼Œè‡ªåŠ¨è®¤ä¸º today ä¹Ÿè¦æ¸…
    if include_parking:
        return (True, True)
    
    # æ£€æµ‹åŸºæœ¬çš„"å…¨éƒ¨å®Œæˆ"
    all_done_patterns = [
        r"æ‰€æœ‰.{0,5}(?:éƒ½|å…¨|å·²).{0,5}(?:åšå®Œ|å®Œæˆ|æå®š)",
        r"(?:éƒ½|å…¨éƒ¨|å…¨).{0,5}(?:åšå®Œ|å®Œæˆ|æå®š)",
        r"(?:åšå®Œ|å®Œæˆ|æå®š).{0,5}(?:æ‰€æœ‰|å…¨éƒ¨|éƒ½)",
        r"æ¸…ç©ºäº†",
        r"å…¨æ¸…äº†",
    ]
    
    today_done = False
    for pattern in all_done_patterns:
        if re.search(pattern, text):
            today_done = True
            break
    
    return (today_done, False)


def detect_completed_items(text: str) -> List[str]:
    """æ£€æµ‹ç”¨æˆ·è¾“å…¥ä¸­çš„å®Œæˆè¯­å¥"""
    completed = []
    # å¸¸è§çš„å®Œæˆè¡¨è¾¾
    patterns = [
        r"(?:åšå®Œäº†|å®Œæˆäº†|æå®šäº†|å¼„å¥½äº†|å†™å®Œäº†|äº¤äº†|å‘äº†|æ‰“äº†|å›äº†|æ”¹å®Œäº†)[:ï¼š]?\s*(.+?)(?:[,ï¼Œã€‚\n]|$)",
        r"(.+?)(?:åšå®Œäº†|å®Œæˆäº†|æå®šäº†|å¼„å¥½äº†|å†™å®Œäº†)",
    ]
    for pattern in patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        for m in matches:
            item = m.strip()
            if item and len(item) < 50:  # åˆç†é•¿åº¦
                completed.append(item)
    return list(set(completed))[:3]  # æœ€å¤š3ä¸ª


@app.post("/api/capture")
async def capture(req: CaptureRequest):
    """è¿½åŠ æ–‡æœ¬åˆ° state.md é¡¶éƒ¨ï¼Œç„¶åé‡æ’"""
    raw_state = read_text(STATE_PATH)
    meta = get_metadata(raw_state)
    style = get_praise_style()
    
    # å…ˆè§£æå½“å‰çŠ¶æ€
    current_state = parse_state_sections(strip_metadata(raw_state))
    today_tasks = current_state.get("today", [])
    parking_tasks = current_state.get("parking", [])
    
    # æ£€æµ‹ç”¨æˆ·æ˜¯å¦è¯´"æ‰€æœ‰äº‹éƒ½åšå®Œäº†"
    today_done, include_parking = detect_all_done(req.text)
    
    if today_done and (today_tasks or parking_tasks):
        # è¿”å›æ‰€æœ‰ä»»åŠ¡ä½œä¸ºå¾…ç¡®è®¤
        all_task_names = [t["name"] for t in today_tasks]
        parking_task_names = [p["name"] for p in parking_tasks] if include_parking else []
        
        return {
            "state": current_state,
            "praise": None,
            "pending_confirm": all_task_names,
            "pending_parking": parking_task_names if include_parking else None,
            "confirm_all": True,  # æ ‡è®°è¿™æ˜¯"å…¨éƒ¨å®Œæˆ"çš„ç¡®è®¤
            "include_parking": include_parking,
        }
    
    # æ£€æµ‹ç”¨æˆ·æ˜¯å¦è¯´å®Œæˆäº†å…·ä½“çš„äº‹
    detected_completed = detect_completed_items(req.text)
    
    _, old_archive = split_done_archive(raw_state)
    old_done_count = len(old_archive)
    
    new_content = f"[{timestamp_human()}] {req.text}\n\n{strip_metadata(raw_state)}"
    if meta:
        new_content = set_metadata(new_content, meta)
    write_text(STATE_PATH, new_content)
    
    result = run_replan()
    
    new_done_count = len(result.get("done", []))
    praise = None
    
    # å¦‚æœæ£€æµ‹åˆ°å®Œæˆé¡¹ï¼Œè¿”å›å¾…ç¡®è®¤åˆ—è¡¨ï¼ˆä¸ç›´æ¥å¤¸ï¼‰
    if detected_completed:
        return {
            "state": result, 
            "praise": None,
            "pending_confirm": detected_completed,
        }
    
    # æ²¡æœ‰æ£€æµ‹åˆ°å®Œæˆé¡¹ï¼Œä½†æ¨¡å‹è¯†åˆ«å‡ºäº†ï¼ˆç›´æ¥å¤¸ï¼‰
    if new_done_count > old_done_count:
        praise = random.choice(PRAISE_POOLS.get(style, PRAISE_POOLS["neutral"]))
    
    return {"state": result, "praise": praise, "pending_confirm": None}


@app.post("/api/complete")
async def complete(req: CompleteRequest):
    """å®ŒæˆæŸä¸ªä»»åŠ¡ï¼Œè¿”å› Aftercare"""
    raw_state = read_text(STATE_PATH)
    meta = get_metadata(raw_state)
    today_str = date.today().isoformat()
    style = get_praise_style()
    
    # Find and mark task as complete
    lines = strip_metadata(raw_state).splitlines()
    new_lines = []
    found = False
    
    for line in lines:
        if req.task_text in line and "**" in line and not found:
            new_lines.append(f"- [x] {req.task_text}")
            found = True
            continue
        if found and line.strip().startswith("â†’"):
            continue
        new_lines.append(line)
    
    if req.note:
        new_lines.insert(0, f"[{timestamp_human()}] å®Œæˆæ„Ÿæƒ³ï¼š{req.note}\n")
    
    new_content = "\n".join(new_lines)
    if meta:
        new_content = set_metadata(new_content, meta)
    write_text(STATE_PATH, new_content)
    
    # Replan
    result = run_replan()
    
    # å¼ºåˆ¶ä» today åˆ—è¡¨ä¸­ç§»é™¤åˆšå®Œæˆçš„ä»»åŠ¡ï¼ˆé˜²æ­¢æ¨¡å‹åˆåŠ å›æ¥ï¼‰
    completed_task_lower = req.task_text.lower()
    result["today"] = [t for t in result.get("today", []) if completed_task_lower not in t.get("name", "").lower()]
    
    # Generate Aftercare response
    praise = random.choice(PRAISE_POOLS.get(style, PRAISE_POOLS["neutral"]))
    
    # Check micro action limit
    current_count = get_micro_action_count()
    
    if current_count >= MAX_MICRO_ACTIONS_PER_DAY:
        # Exceeded limit
        return {
            "state": result,
            "praise": praise,
            "praise_style": style,
            "ask": None,
            "micro_action": None,
            "safety_note": SHUTDOWN_NOTES.get(style, SHUTDOWN_NOTES["neutral"]),
        }
    
    # Select micro action
    micro_action = select_micro_action(req.task_text, result.get("today", []))
    
    return {
        "state": result,
        "praise": praise,
        "praise_style": style,
        "ask": "è¦ä¸è¦é¡ºä¾¿åšä¸ªå°åŠ¨ä½œï¼Ÿ" if micro_action else None,
        "micro_action": micro_action,
        "safety_note": SAFETY_NOTES.get(style, SAFETY_NOTES["neutral"]),
    }


class ConfirmDoneRequest(BaseModel):
    item: str


class CompleteAllRequest(BaseModel):
    tasks: List[str]
    parking_tasks: Optional[List[str]] = None


@app.post("/api/complete_all")
async def complete_all(req: CompleteAllRequest):
    """ä¸€é”®å®Œæˆæ‰€æœ‰ä»»åŠ¡ï¼ˆå¯é€‰åŒ…æ‹¬ parkingï¼‰- ä¸è°ƒç”¨ AIï¼Œç›´æ¥å½’æ¡£"""
    raw_state = read_text(STATE_PATH)
    meta = get_metadata(raw_state)
    style = get_praise_style()
    today_str = date.today().isoformat()
    
    all_tasks = req.tasks + (req.parking_tasks or [])
    
    # è·å–ç°æœ‰å½’æ¡£
    _, existing_archive = split_done_archive(raw_state)
    
    # ä¸ºæ‰€æœ‰ä»»åŠ¡åˆ›å»ºå½’æ¡£æ¡ç›®
    new_done_lines = [f"- [x] {today_str} â€” {task}" for task in all_tasks]
    
    # åˆå¹¶å½’æ¡£ï¼ˆæ–°çš„åœ¨å‰ï¼‰
    combined_archive = dedupe_preserve_order(new_done_lines + existing_archive)
    
    # ç”Ÿæˆç®€æ´çš„æ–° stateï¼ˆä¸è°ƒç”¨ AIï¼‰
    new_state = f"""## ä»Šå¤©åšè¿™å‡ ä»¶å°±å¤Ÿäº†

ï¼ˆå…¨éƒ¨å®Œæˆï¼ğŸ‰ï¼‰

---

## ä»Šå¤©å¯ä»¥ä¸åš

ï¼ˆä¹Ÿå…¨éƒ¨å®Œæˆäº†ï¼ï¼‰

---

## å¦‚æœè¿˜æœ‰ä½™åŠ›

- å¥½å¥½ä¼‘æ¯

{DONE_ARCHIVE_HEADER}
{chr(10).join(combined_archive)}"""
    
    if meta:
        new_state = set_metadata(new_state, meta)
    
    write_text(STATE_PATH, new_state)
    
    # ä¿å­˜å¿«ç…§
    RUNS_DIR.mkdir(exist_ok=True)
    write_text(RUNS_DIR / f"state_{timestamp()}.md", new_state)
    
    # æ›´æ–°å‘¨æŠ¥
    update_weekly_summary(combined_archive)
    
    # è§£æç»“æœ
    result = {
        "today": [],
        "parking": [],
        "extra": ["å¥½å¥½ä¼‘æ¯"],
        "done": [{"date": today_str, "text": t} for t in all_tasks] + 
                [{"date": d.get("date", ""), "text": d.get("text", "")} 
                 for d in parse_state_sections(raw_state).get("done", [])],
    }
    
    # è¿”å›æ­å–œ
    hints = PARKING_HINTS.get(style, PARKING_HINTS["neutral"])
    
    # æ›´å¼ºçƒˆçš„æ­å–œï¼ˆå¦‚æœåŒ…æ‹¬ parkingï¼‰
    if req.parking_tasks:
        super_praise = {
            "snarky": "å…¨æ¸…äº†ï¼Ÿï¼ä½ ä»Šå¤©æ˜¯ä¸æ˜¯åƒäº†ä»€ä¹ˆï¼Ÿå¤ªçŒ›äº†ã€‚",
            "neutral": "æ­å–œï¼Œä»Šå¤©æ‰€æœ‰ä»»åŠ¡ï¼ˆåŒ…æ‹¬å¯é€‰ï¼‰å…¨éƒ¨å®Œæˆã€‚",
            "warm": "å¤ªæ£’äº†ï¼ï¼æ‰€æœ‰æ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆäº†ï¼ä»Šå¤©çš„ä½ è¶…çº§å‰å®³ï¼ğŸ‰",
        }
        praise = super_praise.get(style, super_praise["neutral"])
    else:
        praise = hints["all_done"]
    
    return {
        "state": result,
        "praise": praise,
        "all_done": True,
        "completed_count": len(all_tasks),
        "include_parking": bool(req.parking_tasks),
    }


class CompleteParkingRequest(BaseModel):
    task_name: str
    note: Optional[str] = ""


@app.post("/api/complete_parking")
async def complete_parking(req: CompleteParkingRequest):
    """å®Œæˆ parking ä»»åŠ¡ï¼Œæ ¹æ®æƒ…å†µç»™å‡ºä¸åŒåé¦ˆ"""
    raw_state = read_text(STATE_PATH)
    meta = get_metadata(raw_state)
    style = get_praise_style()
    
    # å…ˆè§£æå½“å‰çŠ¶æ€
    current_state = parse_state_sections(strip_metadata(raw_state))
    today_tasks = current_state.get("today", [])
    parking_tasks = current_state.get("parking", [])
    done_count = len(current_state.get("done", []))
    
    # æ ‡è®°ä»»åŠ¡å®Œæˆ
    lines = strip_metadata(raw_state).splitlines()
    new_lines = []
    found = False
    
    for line in lines:
        # åŒ¹é… parking ä»»åŠ¡è¡Œ (- xxx â€” reason)
        if req.task_name in line and "â€”" in line and not found:
            new_lines.append(f"- [x] {req.task_name}")
            found = True
            continue
        new_lines.append(line)
    
    if req.note:
        new_lines.insert(0, f"[{timestamp_human()}] å®Œæˆæ„Ÿæƒ³ï¼š{req.note}\n")
    
    new_content = "\n".join(new_lines)
    if meta:
        new_content = set_metadata(new_content, meta)
    write_text(STATE_PATH, new_content)
    
    # é‡æ’
    result = run_replan()
    
    # ä» parking ä¸­ç§»é™¤åˆšå®Œæˆçš„
    task_lower = req.task_name.lower()
    result["parking"] = [p for p in result.get("parking", []) if task_lower not in p.get("name", "").lower()]
    
    # åˆ¤æ–­æƒ…å†µ
    hints = PARKING_HINTS.get(style, PARKING_HINTS["neutral"])
    remaining_today = result.get("today", [])
    remaining_parking = result.get("parking", [])
    new_done_count = len(result.get("done", []))
    
    # æƒ…å†µ1ï¼šä¸»çº¿ä»»åŠ¡ä¸€ä¸ªéƒ½æ²¡åšå®Œï¼ˆdone æ•°é‡æ²¡å˜æˆ–åªå¢åŠ äº†åˆšå®Œæˆçš„ parkingï¼‰
    main_done_today = new_done_count - done_count - 1  # å‡å»åˆšå®Œæˆçš„ parking
    
    if len(remaining_today) > 0 and main_done_today <= 0:
        # ä¸»çº¿è¿˜æ²¡åŠ¨
        return {
            "state": result,
            "praise": random.choice(PRAISE_POOLS.get(style, PRAISE_POOLS["neutral"])),
            "praise_style": style,
            "hint": hints["main_first"],
            "hint_type": "main_first",
            "all_done": False,
            "safety_note": SAFETY_NOTES.get(style, SAFETY_NOTES["neutral"]),
        }
    
    # æƒ…å†µ2ï¼šæ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆäº†
    if len(remaining_today) == 0 and len(remaining_parking) == 0:
        return {
            "state": result,
            "praise": hints["all_done"],
            "praise_style": style,
            "hint": None,
            "hint_type": "all_done",
            "all_done": True,
            "safety_note": None,
        }
    
    # æƒ…å†µ3ï¼šä¸»çº¿åšå®Œäº†ï¼Œè¿™ä¸ªæ˜¯é¢å¤–çš„
    if len(remaining_today) == 0:
        # æ¨èä¸€ä¸ª parking ä»»åŠ¡åˆ° todayï¼ˆå¦‚æœè¿˜æœ‰çš„è¯ï¼‰
        recommend = None
        if remaining_parking:
            recommend = remaining_parking[0]
        
        return {
            "state": result,
            "praise": random.choice(PRAISE_POOLS.get(style, PRAISE_POOLS["neutral"])),
            "praise_style": style,
            "hint": hints["bonus"],
            "hint_type": "bonus",
            "all_done": False,
            "recommend_to_today": recommend,
            "safety_note": SAFETY_NOTES.get(style, SAFETY_NOTES["neutral"]),
        }
    
    # é»˜è®¤æƒ…å†µ
    return {
        "state": result,
        "praise": random.choice(PRAISE_POOLS.get(style, PRAISE_POOLS["neutral"])),
        "praise_style": style,
        "hint": None,
        "hint_type": None,
        "all_done": False,
        "safety_note": SAFETY_NOTES.get(style, SAFETY_NOTES["neutral"]),
    }


@app.post("/api/confirm_done")
async def confirm_done(req: ConfirmDoneRequest):
    """ç”¨æˆ·ç¡®è®¤å®ŒæˆæŸäº‹ï¼Œå½’æ¡£å¹¶è¿”å›å¤¸å¤¸"""
    raw_state = read_text(STATE_PATH)
    meta = get_metadata(raw_state)
    today_str = date.today().isoformat()
    style = get_praise_style()
    
    # æ·»åŠ å®Œæˆé¡¹åˆ° state
    done_line = f"- [x] {req.item}"
    new_content = f"{done_line}\n\n{strip_metadata(raw_state)}"
    if meta:
        new_content = set_metadata(new_content, meta)
    write_text(STATE_PATH, new_content)
    
    # é‡æ’
    result = run_replan()
    
    # å¼ºåˆ¶ä» today åˆ—è¡¨ä¸­ç§»é™¤åˆšå®Œæˆçš„ä»»åŠ¡
    completed_item_lower = req.item.lower()
    result["today"] = [t for t in result.get("today", []) if completed_item_lower not in t.get("name", "").lower()]
    
    # è¿”å›å¤¸å¤¸ + Aftercare
    praise = random.choice(PRAISE_POOLS.get(style, PRAISE_POOLS["neutral"]))
    
    current_count = get_micro_action_count()
    if current_count >= MAX_MICRO_ACTIONS_PER_DAY:
        return {
            "state": result,
            "praise": praise,
            "praise_style": style,
            "ask": None,
            "micro_action": None,
            "safety_note": SHUTDOWN_NOTES.get(style, SHUTDOWN_NOTES["neutral"]),
        }
    
    micro_action = select_micro_action(req.item, result.get("today", []))
    
    return {
        "state": result,
        "praise": praise,
        "praise_style": style,
        "ask": "è¦ä¸è¦é¡ºä¾¿åšä¸ªå°åŠ¨ä½œï¼Ÿ" if micro_action else None,
        "micro_action": micro_action,
        "safety_note": SAFETY_NOTES.get(style, SAFETY_NOTES["neutral"]),
    }


@app.post("/api/accept_micro")
async def accept_micro(req: MicroActionRequest):
    """User accepted micro action"""
    # Increment counter
    increment_micro_action_count()
    
    # Append to state.md
    raw_state = read_text(STATE_PATH)
    meta = get_metadata(raw_state)
    
    new_content = f"[{timestamp_human()}] æˆ‘é€‰æ‹©é¡ºä¾¿åšï¼š{req.action_title}\n\n{strip_metadata(raw_state)}"
    if meta:
        new_content = set_metadata(new_content, meta)
    write_text(STATE_PATH, new_content)
    
    # Replan
    result = run_replan()
    return {"state": result}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000)
